---
title: "Analysis_Final_SocCult"
author: "Louise & Nicole"
date: "18/05/2020"
output:   
  md_document:
    variant: markdown_github
editor_options: 
  chunk_output_type: console

---

### Packages + Functions
```{r setup, include=FALSE}
pacman::p_load(
  rethinking,
  brms,
  tidyverse,
  bayesplot,
  viridis,
  dplyr,
  data.table,
  ggplot2,
  BayesCombo,
  patchwork,
  beepr,
  graphics,
  lmerTest,
  loo
)

```


### Explore Data
```{r}
# load data
d <- read.csv("~/Documents/University/4SEMESTER/Social and Cultural Dynamics/EXAM/ANALYSIS/SocCult-Exam/FINAL_DATA.csv")
class(d)

# turn ID into factor
d$ID <- as.factor(d$ID)

# check if any NA's
d[!complete.cases(d), ]

# add log values and log
d$RT_log <- log(d$RT)
summary(d$RT_log)

# add log - ndt for summary 
d$RT_log_ndt <- log(d$RT - 200)
summary(d$RT_log_ndt)

# summary 
summary(d)

# add scaled empathy scores
d$s_totalemp <- scale(d$totalemp)
d$s_cogemp <- scale(d$cogemp)
d$s_affemp <- scale(d$affemp)

# make seperate subsets
y <- subset(d, correctresponse == "yes" & accuracy != "late") #6 late rows removed 
n <- subset(d, correctresponse == "no")
c <- subset(d, accuracy == "correct")
cy <- subset(c, correctresponse == "yes")

mean(cy$totalemp)
sd(cy$totalemp)

mean_totalemp <- cy %>% group_by(ID) %>% 
  summarize(mean(totalemp))

sd(mean_totalemp$`mean(totalemp)`)


# explore data
ggplot(y, aes(x = ID, y = RT, fill = consistency)) + 
         geom_bar(stat = "summary", fun.y = "mean", position = "dodge")

ggplot(y, aes(x = affemp, y = RT, fill = consistency)) + 
         geom_bar(stat = "summary", fun.y = "mean", position = "dodge")

ggplot(n, aes(x = ID, fill = accuracy, color = consistency)) + 
         geom_bar(position = "dodge")


# calculating sd and mean by of ID means
cy %>% 
  group_by(ID) %>% 
  summarise(mean = mean(RT_log_ndt))

# calculate how many late ones
subset(d, accuracy == "late") %>% 
  group_by(ID) %>% 
  summarize(n())

# calculate accuracy by consistency and condition
y %>% 
  group_by(consistency, condition, accuracy) %>%
  summarize(n())

```

#Participant Summary
```{r}
# sumamrize by participant
summary <- d %>% 
  group_by(d$ID) %>% 
  summarise(gender = gender[1], age = mean(age), language = native[1], late = n())

# age
mean(summary$age)

# native language 
summary %>% 
  group_by(language) %>% 
  summarize(n())

```


#H1 - RT 
```{r}

# PRIORS + MODEL --------------------

# define formula
RT_f <- bf(RT|trunc(ub = 2000) ~ 0 + condition + condition : consistency + (0 + condition + condition : consistency|ID))

# get priors
get_prior(RT_f, cy, family = shifted_lognormal())

# define priors
RT_prior_f <- c(
  prior(normal(6.3, 0.2), class = b, coef = conditionA),
  prior(normal(6.3, 0.2), class = b, coef = conditionO),
  prior(normal(0, 0.2), class = b, coef = conditionA:consistencyincon),
  prior(normal(0, 0.2), class = b, coef = conditionO:consistencyincon),
  prior(normal(0, 0.2), class = sigma),
  prior(normal(0, 0.2), class = sd),
  prior(lkj(1), class = cor)
)

# prior model
RT_prior_m <- brm(
  RT_f,
  cy,
  family = shifted_lognormal(),
  prior = RT_prior_f,
  sample_prior = "only",
  seed = 28,
  chains = 4,
  cores = 3,
  iter = 4000,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))
 
# prior check
pp_check(RT_prior_m, nsamples = 1000)
  
# run model
RT_m <- brm(
  RT_f,
  cy,
  family = shifted_lognormal(),
  prior = RT_prior_f,
  sample_prior = T,
  seed = 28,
  chains = 4,
  cores = 3,
  iter = 4000,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))

# QUALITY CHECK --------------------
  
# summary/quality check
summary(RT_m) 

# posterior checks 
pp_check(RT_m, nsamples = 1000)
  
# MCMC trace and rank trace plots
color_scheme_set("viridis")
mcmc_trace(RT_m, pars = vars(-contains("["), -contains("prior"), -contains("lp"))) + theme_classic()
mcmc_rank_overlay(RT_m, pars = vars(-contains("["), -contains("prior"), -contains("lp"))) + theme_classic()

#posterior update check (Has the posterior learned from the prior?)
plot(hypothesis(RT_m,"conditionA > 0")) # intercept for arrow
plot(hypothesis(RT_m,"conditionO > 0")) # intercept for other

plot(hypothesis(RT_m,"conditionA:consistencyincon > 0")) # beta for consistency
plot(hypothesis(RT_m,"conditionO:consistencyincon > 0")) # beta for consistency

plot(hypothesis(RT_m, "conditionA > 0", class = "sd", group = "ID")) #varyig intercept for arrow
plot(hypothesis(RT_m, "conditionO > 0", class = "sd", group = "ID")) #varyig intercept other
plot(hypothesis(RT_m, "conditionA:consistencyincon > 0", class = "sd", group = "ID")) #varyig slope for arrow
plot(hypothesis(RT_m, "conditionO:consistencyincon > 0", class = "sd", group = "ID")) #varyig slope other

# prior-posterior distributions
prior <- prior_samples(RT_m)
post <- posterior_samples(RT_m)

#prior-posterior plot for sigma
plot(density(prior$sigma), ylim=c(0,40), lty = 3, main = "RT_M: Posterior and prior distribution for sigma")
lines(density(post$sigma), lty = 1)

# HYPOTHESIS TESTING --------------------

# testing difference in baseline/intercept - consistent trials
plot(hypothesis(RT_m,"conditionO = conditionA"))
hypothesis(RT_m,"conditionO = conditionA")

# testing difference in consistency effect - difference between consistent/inconsistent
plot(hypothesis(RT_m,"conditionO:consistencyincon > conditionA:consistencyincon"))
hypothesis(RT_m,"conditionO:consistencyincon > conditionA:consistencyincon")

#translate log into real values
exp(6.13 + 0.07) - exp(6.13) 
exp(6.15 + 0.03) - exp(6.15)

#make predictions
cy$pred <- predict(RT_m)
pred <- cy %>% 
  group_by(ID, condition, consistency) %>% 
  summarize(mean = mean(pred[,1]), sd = sd(pred[,1]), se = sd(pred[,1])/sqrt(sum(!is.na(pred[,1]))), sum = sum(!is.na(pred[,1])))

pred %>% 
  group_by(condition, consistency) %>% 
  summarize(meanx = mean(mean), sd = sd(mean), se = sd(mean)/sqrt(37), sum = sum(mean))


#arrow: 715, 725
#avatar: 725, 734 

#arrow: 711, 745
#avatar: 723, 738

```

#H1 - Error
```{r}

# PRIORS + MODEL --------------------

# define formula
E_f <- bf(accuracy ~ 0 + condition + condition : consistency + (0 + condition + condition : consistency|ID))

# get priors
get_prior(E_f, y, family = bernoulli())

# define priors
E_prior_f <- c(
  prior(normal(-2, 1.5), class = b, coef = conditionA),
  prior(normal(-2, 1.5), class = b, coef = conditionO),
  prior(normal(0, 1.5), class = b, coef = conditionA:consistencyincon),
  prior(normal(0, 1.5), class = b, coef = conditionO:consistencyincon),
  prior(normal(0, 1.5), class = sd),
  prior(lkj(1), class = cor)
)

# prior model
E_prior_m <- brm(
  E_f,
  y,
  family = bernoulli(),
  prior = E_prior_f,
  sample_prior = "only",
  seed = 28,
  chains = 4,
  cores = 3,
  iter = 4000,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))
 
# prior check
pp_check(E_prior_m, nsamples = 1000)

# other prior check
y_pred <- posterior_linpred(E_prior_m)
dens(inv_logit(y_pred))  

# run model
E_m <- brm(
  E_f,
  y,
  family = bernoulli(),
  prior = E_prior_f,
  sample_prior = T,
  seed = 28,
  chains = 4,
  cores = 3,
  iter = 4000,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))
 
# QUALITY CHECK --------------------

# summary/quality check
summary(E_m) 
inv_logit(-2.54)
inv_logit(0.19)
inv_logit(0.17)

# posterior checks 
pp_check(E_m, nsamples = 1000)
  
# MCMC trace and rank trace plots
color_scheme_set("blue")
mcmc_trace(E_m, pars = vars(-contains("["), -contains("prior"), -contains("lp"))) + theme_classic()
mcmc_rank_overlay(E_m, pars = vars(-contains("["), -contains("prior"), -contains("lp"))) + theme_classic()
  
# other posterior check
y_pred <- posterior_linpred(E_m)
dens(inv_logit(y_pred))

## posterior update check (Has the posterior learned from the prior?)
plot(hypothesis(E_m,"conditionA > 0")) # intercept for arrow
plot(hypothesis(E_m,"conditionO > 0")) # intercept for other

plot(hypothesis(E_m,"conditionA:consistencyincon > 0")) # beta for consistency
plot(hypothesis(E_m,"conditionO:consistencyincon > 0")) # beta for consistency

plot(hypothesis(E_m, "conditionA > 0", class = "sd", group = "ID")) #varyig intercept for arrow
plot(hypothesis(E_m, "conditionO > 0", class = "sd", group = "ID")) #varyig intercept other
plot(hypothesis(E_m, "conditionA:consistencyincon > 0", class = "sd", group = "ID")) #varyig slope for arrow
plot(hypothesis(E_m, "conditionO:consistencyincon > 0", class = "sd", group = "ID")) #varyig slope other

plot(hypothesis(E_m, "ID__conditionA__conditionO > 0", class = "cor")) #varyig intercept for arrow
plot(hypothesis(E_m, "ID__conditionA__conditionA:consistencyincon > 0", class = "cor")) #varyig intercept for arrow
plot(hypothesis(E_m, "ID__conditionA__conditionA:consistencyincon > 0", class = "cor"))

#prior-posterior distributions
prior <- prior_samples(E_m)
post <- posterior_samples(E_m)

#prior-posterior plot for sigma
plot(density(prior$sigma), ylim=c(0,40), lty = 3, main = "E_M: Posterior and prior distribution for sigma")
lines(density(post$sigma), lty = 1)

# HYPOTHESIS TESTING --------------------

plot(conditional_effects(E_m), method = "fitted")

# testing difference in baseline condition/consistent trials
plot(hypothesis(E_m,"conditionO > conditionA"))
hypothesis(E_m,"conditionO > conditionA")

# testing difference in consistency effect 
plot(hypothesis(E_m,"conditionO:consistencyincon > conditionA:consistencyincon"))
hypothesis(E_m,"conditionO:consistencyincon > conditionA:consistencyincon")
plot(hypothesis(RT_m,"conditionO:consistencyincon = conditionA:consistencyincon"))
hypothesis(E_m,"conditionO:consistencyincon < conditionA:consistencyincon")
hypothesis(E_m,"conditionO:consistencyincon = conditionA:consistencyincon")

plot(conditional_effects(E_m))

inv_logit(-2.54)
inv_logit(-2.54-1.48)

inv_logit(-2.65)
inv_logit(-2.65-1.11)

# make predictions
p1 <- predict(E_m, type = "response")
p2 <- predict(E_m)

mean(p1[,1])
mean(p2[,1])

#predictions II
y$predE <- predict(E_m)
one <- y %>% 
  group_by(ID, condition, consistency) %>% 
  summarize(mean = mean(predE[,1]*100), sd = sd(predE[,1]*100), se = sd(predE[,1]*100)/sqrt(sum(!is.na(predE[,1]))), sum =sum(!is.na(predE[,1]))) 

one %>% 
  group_by(condition, consistency) %>% 
  summarize(meanx = mean(mean), sd = sd(mean), se = sd(mean)/sqrt(sum(!is.na(mean))), sum =sum(!is.na(mean))) 


```


#H1 Plots for RT and Error
```{r}

# RT ------------
summary(cy)

# calculate mean and sd for conditions and id
group <- cy %>% group_by(ID, condition, consistency) %>% 
  summarize(mean = mean(RT))

# calculate mean of means + se
cy_meansd <- group %>% group_by(condition, consistency) %>% 
  summarize(meanz = mean(mean), se = sd(mean)/sqrt(sum(!is.na(mean))), sum = sum(!is.na(mean)))
            
# change names
cy_meansd$condition <- ifelse(cy_meansd$condition == "A", "Arrow (Non-Social)", "Avatar (Social)")
cy_meansd$consistency <- ifelse(cy_meansd$consistency == "con", "Consistent", "Inconsistent")

# make plot
ggplot(cy_meansd, aes(x=condition, y=meanz, fill= consistency)) + 
  geom_bar(stat="identity", position=position_dodge()) +
  geom_errorbar(aes(ymin=meanz-se, ymax=meanz+se), width = 0.2, position=position_dodge(.9)) +
  labs(title = "Mean Reaction Time for Arrow and Avatar Condition\nin Consistent and Inconsistent Trials",  
       x="Condition", y = "Mean RT in ms", leged = "Consistency") +
  scale_fill_manual(name = "Consistency", values=c("lightskyblue","firebrick1")) +
  coord_cartesian(ylim=c(500,760)) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

# Error ------------
# make subset, calculate mean for ids
percE <- y %>% 
  group_by(ID, consistency, condition) %>% 
  summarize(incorrect = length(which(accuracy == "incorrect")), 
            correct = length(which(accuracy == "correct")),
            ratio = (incorrect/(correct+incorrect)*100))

# calculate mean and se of IDs
percEmean <- percE %>% group_by(condition, consistency) %>% 
  summarize(mean = mean(ratio), 
            sd = sd(ratio), 
            se = sd(ratio)/sqrt(37),
            sum = sum(!is.na(ratio)))


# change names
percEmean$condition <- ifelse(percEmean$condition == "A", "Arrow (Non-Social)", "Avatar (Social)")
percEmean$consistency <- ifelse(percEmean$consistency == "con", "Consistent", "Inconsistent")

# make plot
ggplot(percEmean, aes(x=condition, y=mean, fill= consistency)) + 
  geom_bar(stat="identity", position=position_dodge()) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.2,position=position_dodge(.9)) +
  labs(title = "Mean Probability of an Error for Arrow and Avatar Condition\nin Consistent and Inconsistent Trials", x="Condition", y = "Mean Probability of an Error in %", legend = "Consistency") +
  theme_bw() +
  scale_fill_manual(name = "Consistency", values=c("lightskyblue","firebrick1"))+
  theme(plot.title = element_text(hjust = 0.5)) 

```


#H2 and H2.1: RT
```{r}

# PREPROCESSING --------------------

# preprocessing / getting the varying slope distributions for each participnat
full_varyslope_RT <- data.frame(ranef(RT_m, summary = F))[,198]

# summarised vary slopes values
sum_varyslope_RT <- data.frame(ranef(RT_m, summary = T))[,13:14]
sum_varyslope_RT$ID <- as.factor(c(1:37))
names(sum_varyslope_RT)[1] <- "vary_slope_RT"
names(sum_varyslope_RT)[2] <- "error"

# merge the correct/yes data frame from RT with the empathy scores, which are scaled
cy_emp <- merge(x = sum_varyslope_RT, y = cy[,c("ID", "s_totalemp", "s_affemp", "s_cogemp", "totalemp")], by = "ID")

# had all lines multiple times, so just summarise
cy_emp <- cy_emp %>% 
  group_by(ID) %>% 
  summarize(vary_slope_RT = mean(vary_slope_RT), 
            error = mean(error), 
            s_totalemp = mean(s_totalemp),
            s_affemp = mean(s_affemp),
            s_cogemp = mean(s_cogemp),
            totalemp = mean(totalemp))


# scale the slopes
cy_emp$s_slope_RT <- scale(cy_emp$vary_slope_RT)[,]


# PRIORS FOR ALL EMPATHY MODELS --------------------

# define models for the different empathy scales, predicting the slope by empathy 
RT_totalemp_vary <- bf(s_slope_RT ~ 1 + s_totalemp)
RT_cogemp_vary <- bf(s_slope_RT ~ 1 + s_cogemp)
RT_affemp_vary <- bf(s_slope_RT ~ 1 + s_affemp)

# define priors (same for all 
get_prior(RT_totalemp_vary, cy_emp, family = gaussian)
RT_emp_prior <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 1), class = b),
  prior(normal(0, 1), class = sigma)
)

# prior model for total empathy
RT_total_prior_m <- brm(
  formula = RT_totalemp_vary,
  data = cy_emp,
  family = gaussian(),
  prior = RT_emp_prior,
  sample_prior = "only",
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))

# prior check
pp_check(RT_total_prior_m, nsamples = 1000)

# prior model for cognitive empathy
RT_cog_prior_m <- brm(
  formula = RT_cogemp_vary,
  data = cy_emp,
  family = gaussian(),
  prior = RT_emp_prior,
  sample_prior = "only",
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))

# prior check
pp_check(RT_cog_prior_m, nsamples = 1000)

# prior model for affective empathy
RT_aff_prior_m <- brm(
  formula = RT_affemp_vary,
  data = cy_emp,
  family = gaussian(),
  prior = RT_emp_prior,
  sample_prior = "only",
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))

# prior check
pp_check(RT_aff_prior_m, nsamples = 1000)


# ALL EMPATHY MODELS --------------------

# model for total empathy
RT_total_m <- brm(
  formula = RT_totalemp_vary,
  data = cy_emp,
  family = gaussian(),
  prior = RT_emp_prior,
  sample_prior = T,
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))

# model for cognitive empathy
RT_cog_m <- brm(
  formula = RT_cogemp_vary,
  data = cy_emp,
  family = gaussian(),
  prior = RT_emp_prior,
  sample_prior = T,
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))

# model for affective empathy
RT_aff_m <- brm(
  formula = RT_affemp_vary,
  data = cy_emp,
  family = gaussian(),
  prior = RT_emp_prior,
  sample_prior = T,
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))


# QUALITY CHECKS FOR ALL MODELS --------------------
# mcmc plots
color_scheme_set(scheme = "blue")
mcmc_trace(RT_total_m, pars = vars(-contains("["), -contains("prior"), -contains("lp"))) + theme_classic()
mcmc_rank_overlay(RT_total_m, pars = vars(-contains("["), -contains("prior"), -contains("lp")))

# prior and posterior checks togehter (430, 800)
pp_check(RT_total_prior_m, nsamples = 1000) + pp_check(RT_total_m, nsamples = 1000)
pp_check(RT_cog_prior_m, nsamples = 1000) + pp_check(RT_cog_m, nsamples = 1000)
pp_check(RT_aff_prior_m, nsamples = 1000) + pp_check(RT_aff_m, nsamples = 1000)

# summaries
print(summary(RT_total_m), digits = 5)
print(summary(RT_cog_m), digits = 5)
print(summary(RT_aff_m), digits = 5)

# prior posterior distributions of betas
plot(hypothesis(RT_total_m,"s_totalemp > 0"))
plot(hypothesis(RT_cog_m,"s_cogemp > 0"))
plot(hypothesis(RT_aff_m,"s_affemp > 0"))

# prior-posterior distributions for total - intercept
prior <- prior_samples(RT_total_m)
post <- posterior_samples(RT_total_m)
# prior-posterior plot for intercept
plot(density(prior$Intercept), ylim=c(0,3), lty = 3, main = "Prior and Posterior Distribution of Intercept")
lines(density(post$b_Intercept), lty = 1)

# prior-posterior distributions for cog - intercept
prior <- prior_samples(RT_cog_m)
post <- posterior_samples(RT_cog_m)
# prior-posterior plot for intercept
plot(density(prior$Intercept), ylim=c(0,3), lty = 3)
lines(density(post$b_Intercept), lty = 1)

# prior-posterior distributions for aff - intercept
prior <- prior_samples(RT_aff_m)
post <- posterior_samples(RT_aff_m)
# prior-posterior plot for intercept
plot(density(prior$Intercept), ylim=c(0,3), lty = 3)
lines(density(post$b_Intercept), lty = 1)

# plots for paper (with title for total)
p1 <- plot(hypothesis(RT_total_m, c("s_totalemp > 0"), plot = F, theme = theme_get()))[[1]]
p1 +
  ggtitle(label = "Prior and Posterior Distributions\nof Fixed Effect Estimates") +
  theme(plot.title = element_text(hjust = 0.5))


# H2: HYPOTHESIS TESTING --------------------

# testing if there is a credible effect of total empathy on vary slopes
plot(hypothesis(RT_total_m,"s_totalemp > 0"))
hypothesis(RT_total_m,"s_totalemp > 0")


# H2.1: MODEL COMPARISON --------------------

# add criterions
RT_total_m <- add_criterion(RT_total_m, criterion = "loo", reloo = T)
RT_cog_m <- add_criterion(RT_cog_m, criterion = "loo", reloo = T)
RT_aff_m <- add_criterion(RT_aff_m, criterion = "loo", reloo = T)

# compare out of sample error
comparloo_compare(RT_total_m, RT_cog_m, RT_aff_m)
# compare stacking weights
loo_model_weights(RT_total_m, RT_cog_m, RT_aff_m)

#test pareto k 
test <- loo(RT_total_m)
pareto_k_table(loo(RT_aff_m))

```

#H2 and H2.1 Plots: RT
```{r}

# H2 Plot RT --------------------

# plot for total empathy
emp_RT <- ggplot(data = cy_emp, aes(y = s_slope_RT, x = s_totalemp)) + 
  geom_point() + 
  geom_smooth(aes(y = s_slope_RT, x = s_totalemp), method = lm, color = "black", level = 0.9) +
  labs(title = "Relation between Scaled Total Empathy Scores\nand Scaled Varying Slopes (RT)", x="Scaled Total Empathy Scores", y = "Scaled Varying Slopes from Model 1.1 (RT)") +
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5)) +
  coord_cartesian(ylim=c(-2.25,3.25))


# plot for all empathy sclaes
colors <- c("Total Empathy" = "black", "Cognitive Empathy" = "firebrick1", "Affective Empathy" = "deepskyblue3")
all_emp_RT <- ggplot(data = cy_emp) + 
  # total emp
  geom_point(aes(y = s_slope_RT, x = s_totalemp, color = "Total Empathy")) + 
  geom_smooth(aes(y = s_slope_RT, x = s_totalemp), method = lm, color = "black", level = 0.9, alpha = 0.2) +
  #cognitive
  geom_point(aes(y = s_slope_RT, x = s_cogemp, color = "Cognitive Empathy")) + 
  geom_smooth(aes(y = s_slope_RT, x = s_cogemp), method = lm, color = "firebrick1", level = 0.9, alpha = 0.2) +
  # affective
  geom_point(aes(y = s_slope_RT, x = s_affemp, color = "Affective Empathy")) + 
  geom_smooth(aes(y = s_slope_RT, x = s_affemp), method = lm, color = "deepskyblue3", level = 0.9, alpha = 0.2) +
  labs(title = "Relation between Scaled Empathy Scores\nand Scaled Varying Slopes (RT)", 
       x="Scaled Empathy Scores", 
       y = "Scaled Varying Slopes from Model 1.1 (RT)",
       color = "Empathy Scale") +
  scale_color_manual(values = colors) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  legend_none() +
  coord_cartesian(ylim=c(-2.25,3.25))


```


#H2 and H2.1: Error
```{r}

# PREPROCESSING --------------------

# get verying slopes from error data frame
sum_varyslope_E <- data.frame(ranef(E_m, summary = T))[,13:14]
sum_varyslope_E$ID <- as.factor(c(1:37))
names(sum_varyslope_E)[1] <- "vary_slope_E"
names(sum_varyslope_E)[2] <- "error"
y_emp <- merge(x = sum_varyslope_E, y = y[,c("ID", "s_totalemp", "s_affemp", "s_cogemp")], by = "ID")
y_emp <- y_emp %>% 
  group_by(ID) %>% 
  summarize(vary_slope_E = mean(vary_slope_E), 
            error = mean(error), 
            s_totalemp = mean(s_totalemp),
            s_affemp = mean(s_affemp),
            s_cogemp = mean(s_cogemp))

y_emp$s_vary_slope_E <- scale(y_emp$vary_slope_E)[,]

# PRIORS FOR ALL EMPATHY MODELS --------------------

# define models
E_totalemp_vary <- bf(s_vary_slope_E ~ 1 + s_totalemp)
E_cogemp_vary <- bf(s_vary_slope_E ~ 1 + s_cogemp)
E_affemp_vary <- bf(s_vary_slope_E ~ 1 + s_affemp)

# define priors
get_prior(E_totalemp_vary, y_emp, family = gaussian)
E_emp_prior <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 1), class = b),
  prior(normal(0, 1), class = sigma)
)

# test priors
# total empathy 
E_total_prior_m <- brm(
  formula = E_totalemp_vary,
  data = y_emp,
  family = gaussian(),
  prior = E_emp_prior,
  sample_prior = "only",
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))

# prior check
pp_check(E_total_prior_m, nsamples = 1000)

# cognitive empathy 
E_cog_prior_m <- brm(
  formula = E_cogemp_vary,
  data = y_emp,
  family = gaussian(),
  prior = E_emp_prior,
  sample_prior = "only",
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))

# prior check
pp_check(E_cog_prior_m, nsamples = 1000)

# affective empathy 
E_aff_prior_m <- brm(
  formula = E_affemp_vary,
  data = y_emp,
  family = gaussian(),
  prior = E_emp_prior,
  sample_prior = "only",
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))

# prior check
pp_check(E_aff_prior_m, nsamples = 1000)


# ALL EMPATHY MODELS --------------------

# total empathy 
E_total_m <- brm(
  formula = E_totalemp_vary,
  data = y_emp,
  family = gaussian(),
  prior = E_emp_prior,
  sample_prior = T,
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))

# cognitive empathy 
E_cog_m <- brm(
  formula = E_cogemp_vary,
  data = y_emp,
  family = gaussian(),
  prior = E_emp_prior,
  sample_prior = T,
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))

# affective empathy 
E_aff_m <- brm(
  formula = E_affemp_vary,
  data = y_emp,
  family = gaussian(),
  prior = E_emp_prior,
  sample_prior = T,
  chains = 4,
  cores = 3,
  iter = 4000,
  seed = 28,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))


# QUALITY CHECKS FOR ALL MODELS --------------------
#prior and posterior checks together 
pp_check(E_total_prior_m, nsamples = 1000) + pp_check(E_total_m, nsamples = 1000)
pp_check(E_cog_prior_m, nsamples = 1000) + pp_check(E_cog_m, nsamples = 1000)
pp_check(E_aff_prior_m, nsamples = 1000) + pp_check(E_aff_m, nsamples = 1000)

# mcmc plots (only for total)
color_scheme_set(scheme = "blue")
mcmc_trace(E_total_m, pars = vars(-contains("["), -contains("prior"), -contains("lp"))) + theme_classic()
mcmc_rank_overlay(E_total_m, pars = vars(-contains("["), -contains("prior"), -contains("lp"))) + theme_classic()

# summaries
summary(E_total_m)
summary(E_cog_m)
summary(E_aff_m)

# prior posterior
plot(hypothesis(E_total_m,"s_totalemp > 0"))
plot(hypothesis(E_cog_m,"s_cogemp > 0"))
plot(hypothesis(E_aff_m,"s_affemp > 0"))

# prior-posterior distributions for intercept
# total
prior <- prior_samples(E_total_m)
post <- posterior_samples(E_total_m)
plot(density(prior$Intercept), ylim=c(0,3), lty = 3, main = "Prior and Posterior Distribution of Intercept")
lines(density(post$b_Intercept), lty = 1)

# cognitive
prior <- prior_samples(E_cog_m)
post <- posterior_samples(E_cog_m)
plot(density(prior$Intercept), ylim=c(0,400), lty = 3)
lines(density(post$b_Intercept), lty = 1)

# affective
prior <- prior_samples(E_aff_m)
post <- posterior_samples(E_aff_m)
plot(density(prior$Intercept), ylim=c(0,400), lty = 3)
lines(density(post$b_Intercept), lty = 1)

#plots for paper
p1 <- plot(hypothesis(E_total_m, c("s_totalemp > 0"), plot = F, theme = theme_get()))[[1]]
p1 +
  ggtitle(label = "Prior and Posterior Distributions\nof Fixed Effect Estimates") +
  theme(plot.title = element_text(hjust = 0.5))


# H2: HYPOTHESIS TESTING --------------------

# testing if there is a credible effect of total empathy on vary slopes of error
plot(hypothesis(E_total_m,"s_totalemp > 0"))
hypothesis(E_total_m,"s_totalemp > 0")

exp(0.08)

# H2.1: MODEL COMPARISON --------------------

# add criterion
E_total_m <- add_criterion(E_total_m, criterion = "loo", reloo = T)
E_cog_m <- add_criterion(E_cog_m, criterion = "loo", reloo = T)
E_aff_m <- add_criterion(E_aff_m, criterion = "loo", reloo = T)

# compare out og sample error
loo_compare(E_total_m, E_cog_m, E_aff_m)
# compare stacking weights
loo_model_weights(E_total_m, E_cog_m, E_aff_m)


```


#H2 and H2.1 Plots: Error
```{r}

# H2 Plot Error --------------------

# plot total empathy - error
emp_E <- ggplot(data = y_emp, aes(y = s_vary_slope_E, x = s_totalemp)) + 
  geom_point() + 
  geom_smooth(aes(y =s_vary_slope_E, x = s_totalemp), method = lm, color = "black", level = 0.9) +
  labs(title = "Relation between Scaled Total Empathy Scores\nand Scaled Varying Slopes (Error)", x="Scaled Total Empathy Scores", y = "Scaled Varying Slopes from Model 1.2 (Error)") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  coord_cartesian(ylim=c(-2.25,3.25))

emp_RT + emp_E

# plot for all empathy - error
colors <- c("Total Empathy" = "black", "Cognitive Empathy" = "firebrick1", "Affective Empathy" = "deepskyblue3")
allemp_E <- ggplot(data = y_emp) + 
  #total emp
  geom_point(aes(y = s_vary_slope_E, x = s_totalemp, color = "Total Empathy")) + 
  geom_smooth(aes(y = s_vary_slope_E, x = s_totalemp), method = lm, color = "black", level = 0.9, alpha = 0.2) +
  #cognitive
  geom_point(aes(y = s_vary_slope_E, x = s_cogemp, color = "Cognitive Empathy")) + 
  geom_smooth(aes(y = s_vary_slope_E, x = s_cogemp), method = lm, color = "firebrick1", level = 0.9, alpha = 0.2) +
  #affective
  geom_point(aes(y = s_vary_slope_E, x = s_affemp, color = "Affective Empathy")) + 
  geom_smooth(aes(y = s_vary_slope_E, x = s_affemp), method = lm, color = "deepskyblue3", level = 0.9, alpha = 0.2) +
  labs(title = "Relation between Scaled Empathy Scores\nand Scaled Varying Slopes (Error)", 
       x="Scaled Empathy Scores", 
       y = "Scaled Varying Slopes from Model 1.2 (Error)", 
       color = "Empathy Scale") +
  scale_color_manual(values = colors) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  coord_cartesian(ylim=c(-2.25,3.25))

all_emp_RT + allemp_E

```


#PRE: Yes/No Trial Differences Exploration
```{r}
# exploration 
# RT by accuracy, correct repsonse and consistency (yes/no)
d %>% group_by(correctresponse, accuracy, consistency) %>% 
  summarize(RT = mean(RT))

# Error by accuracy, correct repsonse and consistency (yes/no)
d %>% group_by(correctresponse, accuracy, consistency) %>% 
  summarize(n())
```

#PRE: H1 - RT - yes/no with 4 intercepts
```{r}
#RT_formula/model_yes/no_response

# define formula
RT_fyn_r <- bf(RT|trunc(ub = 2000) ~ 0 + condition:correctresponse + condition : consistency : correctresponse + 
                 (0 + condition:correctresponse + condition : consistency : correctresponse|ID))

# get priors
get_prior(RT_fyn_r, c, family = shifted_lognormal())

#define priors
RT_prior_fyn_r <- c(
  prior(normal(6.4, 0.2), class = b, coef = conditionA:correctresponseno),
  prior(normal(6.4, 0.2), class = b, coef = conditionA:correctresponseyes),
  prior(normal(6.4, 0.2), class = b, coef = conditionO:correctresponseno),
  prior(normal(6.4, 0.2), class = b, coef = conditionO:correctresponseyes),
  prior(normal(0, 0.2), class = b, coef = conditionA:correctresponseno:consistencyincon),
  prior(normal(0, 0.2), class = b, coef = conditionA:correctresponseyes:consistencyincon),
  prior(normal(0, 0.2), class = b, coef = conditionO:correctresponseno:consistencyincon),
  prior(normal(0, 0.2), class = b, coef = conditionO:correctresponseyes:consistencyincon),
  prior(normal(0, 0.2), class = sigma),
  prior(normal(0, 0.2), class = sd),
  prior(lkj(1), class = cor)
)

# prior model
RT_prior_myn_r <- brm(
  RT_fyn_r,
  c, #only correct answers
  family = shifted_lognormal(),
  prior = RT_prior_fyn_r,
  sample_prior = "only",
  seed = 28,
  chains = 4,
  cores = 3,
  iter = 4000,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))
 
# prior check
color_scheme_set(scheme = "blue")
pp_check(RT_prior_myn_r, nsamples = 1000)
  
# run actual model
RT_myn_r <- brm(
  formula = RT_fyn_r,
  data = c, 
  family = shifted_lognormal(),
  prior = RT_prior_fyn_r,
  sample_prior = T,
  seed = 28,
  chains = 4,
  cores = 3,
  iter = 4000,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))
  
# summary/quality check
summary(RT_myn_r) 

# prior and posterior checks togehter
pp_check(RT_prior_myn_r, nsamples = 1000) + pp_check(RT_myn_r, nsamples = 1000)
  
# MCMC trace and rank trace plots
color_scheme_set("blue")
mcmc_trace(RT_myn_r, pars = vars(-contains("["), -contains("prior"), -contains("lp"))) + theme_classic()
mcmc_rank_overlay(RT_myn_r, pars = vars(-contains("["), -contains("prior"), -contains("lp"))) + theme_classic()

# prior posterior plots
# intercepts
plot(hypothesis(RT_myn_r, "conditionA:correctresponseno > 0"))
plot(hypothesis(RT_myn_r, "conditionA:correctresponseyes > 0"))
plot(hypothesis(RT_myn_r, "conditionO:correctresponseno > 0"))
plot(hypothesis(RT_myn_r, "conditionO:correctresponseyes > 0"))

# slopes
plot(hypothesis(RT_myn_r, "conditionA:correctresponseno:consistencyincon > 0"))
plot(hypothesis(RT_myn_r, "conditionA:correctresponseyes:consistencyincon > 0"))
plot(hypothesis(RT_myn_r, "conditionO:correctresponseno:consistencyincon > 0"))
plot(hypothesis(RT_myn_r, "conditionO:correctresponseyes:consistencyincon > 0"))

# all together
# all prior/posterior plots togehter for intercepts (for paper)
p1 <- plot(hypothesis(RT_myn_r, c("conditionA:correctresponseno > 0", 
                                 "conditionA:correctresponseyes > 0", 
                                 "conditionO:correctresponseno > 0", 
                                 "conditionO:correctresponseyes > 0"), plot = F, theme = theme_get()))[[1]]
p1 +
  ggtitle(label = "Prior and Posterior Distributions\nof Fixed Effect Estimates (Intercepts)") +
  theme(plot.title = element_text(hjust = 0.5))

# all prior/posterior plots together for slopes (for paper)
p1 <- plot(hypothesis(RT_myn_r, c("conditionA:correctresponseno:consistencyincon > 0",
                                 "conditionA:correctresponseyes:consistencyincon > 0",
                                 "conditionO:correctresponseno:consistencyincon > 0",
                                 "conditionO:correctresponseyes:consistencyincon > 0"), plot = F, theme = theme_get()))[[1]]
p1 +
  ggtitle(label = "Prior and Posterior Distributions\nof Fixed Effect Estimates (Slopes)") +
  theme(plot.title = element_text(hjust = 0.5))

# real hypothesis testing
# intercepts
hypothesis(RT_myn_r, "conditionA:correctresponseno > conditionA:correctresponseyes") 
# longer RT in no in arrow in consistent
hypothesis(RT_myn_r, "conditionO:correctresponseno > conditionO:correctresponseyes") 
# longer RT in no in avatar in consistent

# slopes
hypothesis(RT_myn_r, "conditionA:correctresponseno:consistencyincon < conditionA:correctresponseyes:consistencyincon") 
# less consistency effect in no in arrow
hypothesis(RT_myn_r, "conditionO:correctresponseno:consistencyincon = conditionO:correctresponseyes:consistencyincon")
# pretty much the same consistency effect in avatar

# predictions
c$predictions <- predict(RT_myn_r)
RT_pred <- c %>%
  group_by(condition, consistency, correctresponse) %>%
  summarise(mean_pred = mean(predictions),
  sd_pred = sd(predictions))
RT_pred

# 6ms= arrow: difference between consistent and inconsistent in NO.
# -30ms= arrow: difference between consistent and inconsistent in YES.
# 36= The difference between these two.

# -3= avatar: difference between consistent and inconsistent in NO.
# -12= avatar: difference between consistent and inconsistent in YES.
# 9= The difference between these two.

```

#PRE: H1 - Error - yes/no - with 4 intercepts
```{r}
# pre processing, get mean and sd
percE <- d %>% 
  group_by(ID) %>% 
  summarize(incorrect = length(which(accuracy == "incorrect")), 
            correct = length(which(accuracy == "correct")),
            ratio = incorrect/(correct+incorrect))

mean(percE$ratio) # -2.8440
sd(percE$ratio) # -3.1397

# make dataframe without late responses
d_nolate <- filter(d, d$accuracy == "incorrect" | d$accuracy == "correct")

# define formula
E_fyn_r <- bf(accuracy ~ 0 + condition:correctresponse + condition : consistency : correctresponse + (0 + condition:correctresponse + condition : consistency : correctresponse|ID))

# get prior
get_prior(E_fyn_r, d_nolate, family = bernoulli())

# define priors
E_prior_fyn_r <- c(
  prior(normal(-3, 1.5), class = b, coef = conditionA:correctresponseno),
  prior(normal(-3, 1.5), class = b, coef = conditionA:correctresponseyes),
  prior(normal(-3, 1.5), class = b, coef = conditionO:correctresponseno),
  prior(normal(-3, 1.5), class = b, coef = conditionO:correctresponseyes),
  prior(normal(0, 1.5), class = b, coef = conditionA:correctresponseno:consistencyincon),
  prior(normal(0, 1.5), class = b, coef = conditionA:correctresponseyes:consistencyincon),
  prior(normal(0, 1.5), class = b, coef = conditionO:correctresponseno:consistencyincon),
  prior(normal(0, 1.5), class = b, coef = conditionO:correctresponseyes:consistencyincon),
  prior(normal(0, 1.5), class = sd),
  prior(lkj(1), class = cor) 
)

# prior model
E_prior_myn_r <- brm(
  forumla = E_fyn_r,
  data = d_nolate,
  family = bernoulli(),
  prior = E_prior_fyn_r,
  sample_prior = "only",
  seed = 28,
  chains = 4,
  cores = 3,
  iter = 4000,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))
 
# prior check
pp_check(E_prior_myn_r, nsamples = 1000)
# other prior check
dens(inv_logit(posterior_linpred(E_prior_myn_r)))

# run a actual model
E_myn_r <- brm(
  formula = E_fyn_r,
  data = d_nolate,
  family = bernoulli(),
  prior = E_prior_fyn_r,
  sample_prior = T,
  seed = 28,
  chains = 4,
  cores = 3,
  iter = 4000,
  control = list(
    max_treedepth = 20,
    adapt_delta=0.95))
  
# summary/quality check
summary(E_myn_r) 

# posterior checks 
pp_check(E_myn_r, nsamples = 1000)
# other posterior checks
dens(inv_logit( posterior_linpred(E_myn_r)))
  
# MCMC trace and rank trace plots
color_scheme_set("blue")
mcmc_trace(E_myn_r, pars = vars(-contains("["), -contains("prior"), -contains("lp"))) + theme_classic()
mcmc_rank_overlay(E_myn_r, pars = vars(-contains("["), -contains("prior"), -contains("lp"))) + theme_classic()

# all prior/posterior plots togehter for intercepts (for paper)
p1 <- plot(hypothesis(E_myn_r, c("conditionA:correctresponseno > 0", 
                                 "conditionA:correctresponseyes > 0", 
                                 "conditionO:correctresponseno > 0", 
                                 "conditionO:correctresponseyes > 0"), plot = F, theme = theme_get()))[[1]]
p1 +
  ggtitle(label = "Prior and Posterior Distributions\nof Fixed Effect Estimates (Intercepts)") +
  theme(plot.title = element_text(hjust = 0.5))

# all prior/posterior plots together for slopes (for paper)
p1 <- plot(hypothesis(E_myn_r, c("conditionA:correctresponseno:consistencyincon > 0",
                                 "conditionA:correctresponseyes:consistencyincon > 0",
                                 "conditionO:correctresponseno:consistencyincon > 0",
                                 "conditionO:correctresponseyes:consistencyincon > 0"), plot = F, theme = theme_get()))[[1]]
p1 +
  ggtitle(label = "Prior and Posterior Distributions\nof Fixed Effect Estimates (Slopes)") +
  theme(plot.title = element_text(hjust = 0.5))


# real hypothesig testing
# intercepts
hypothesis(E_myn_r, "conditionA:correctresponseno < conditionA:correctresponseyes") 
# higher prop of error in consistent, arrow in yes
hypothesis(E_myn_r, "conditionO:correctresponseno < conditionO:correctresponseyes") 
# higher prop of error in conssitent, avatar yes

# slopes
hypothesis(E_myn_r, "conditionA:correctresponseno:consistencyincon > conditionA:correctresponseyes:consistencyincon") 
# higher consistency effect in arrow, no
hypothesis(E_myn_r, "conditionO:correctresponseno:consistencyincon > conditionO:correctresponseyes:consistencyincon")
# higher consistency effect in avatar, no

#predictions
d_nolate$predictions <- predict(E_myn_r)
E_pred <- d_nolate %>%
  group_by(condition, consistency, correctresponse) %>%
  summarise(mean_pred = mean(predictions),
  sd_pred = sd(predictions))
E_pred

# 0.126 = arrow: difference between consistent and inconsistent in NO.
# 0.212 = arrow: difference between consistent and inconsistent in YES.
# 0.086 = The difference between these two.

# 0.071 = avatar: difference between consistent and inconsistent in NO.
# 0.161 = avatar: difference between consistent and inconsistent in YES.
# 0.09 = The difference between these two.

```

